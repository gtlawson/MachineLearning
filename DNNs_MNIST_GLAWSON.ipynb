{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks to Identify Handwritten Digits \n",
    "## Gary Lawson - 26 March 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MINST dataset is comprised of thousands of images of handwritten digits ranging from 0 to 9.  Training a data model on labeled data can provide for prediction of future handwritten digits never seen by the model, allowing computer imaging to reduce the need for human interaction in detemining these handwritten characters.  In this experiement, each image is composed of 748 pixel darkeness values aranged in a 28 x 28 matrix of pixels.  Each pixel in the matrix is a feature of its own with a darkness value of 0 to 255, where 0 is white and 255 is black.  The data for this experiment was downloaded from the Kaggle competition named *Digit Recognizer* (link below), and was provided as separate train and test .csv files.\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "The goal of this exercise is to create a neural network experiment design that tests a minimum of two separate experimental factors to identify the best performing model.  The experiments will be evaluated on processing time and the accuracy of both training cross-validation and test predictions.  The results of each design will be submitted to the *Digit Recognizer* Kaggle competition for scoring.    \n",
    "\n",
    "Python will be used in a Jupyter Notebook to explore the data and produce a series of graphical representations to help visualize the survey data as well as develop several models for evaluation. Tensorflow and Keras will be used to generate the neural networks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages have been sucessfully imported.\n"
     ]
    }
   ],
   "source": [
    "# Import base packages into the namespace for this program\n",
    "import numpy as np # for creating and working with arrays\n",
    "import pandas as pd # for creating and working with dataframes\n",
    "from math import sqrt  # for root mean-squared error calculation\n",
    "import time # for recording times on model runs\n",
    "\n",
    "# Modeling routines from Scikit Learn packages\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # metrics for evaluating models\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler # data scaling packages\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, \\\n",
    "                                    KFold, RandomizedSearchCV, GridSearchCV # model selection packages\n",
    "\n",
    "# Import plotting packages\n",
    "import matplotlib.pyplot as plt  # static plotting\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "# Import other packages\n",
    "import pickle  # used for dumping and loading binary files\n",
    "from collections import OrderedDict  # for creating table output\n",
    "\n",
    "# Import Tensorflow neural network model packages\n",
    "import tensorflow as tf\n",
    "#from tensorflow_graph_in_jupyter import show_graph\n",
    "\n",
    "# Import Keras neural network model package\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print('All packages have been sucessfully imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imports successful.\n"
     ]
    }
   ],
   "source": [
    "# Read MNIST data train and test data, creating dataframes for both.\n",
    "train_import = pd.read_csv('train.csv')\n",
    "test_import = pd.read_csv('test.csv')\n",
    "print('Data imports successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature List (including target variable(s)): \n",
      " Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n",
      "\n",
      "Number of Features (including target variable(s):  785\n",
      "\n",
      "DataFrame (first five rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the pandas DataFrame object train_import\n",
    "print('\\nFeature List (including target variable(s)): \\n', train_import.columns)\n",
    "print('\\nNumber of Features (including target variable(s): ', len(train_import.columns))\n",
    "print('\\nDataFrame (first five rows):')\n",
    "train_import.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 1: First Five Rows of Train Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 shows that there are 785 columns provided in the dataset that represent the 784 features and 1 target variable.  This aligns with what is expected from the *Digit Recognizer* Kaggle Competition description.  Additionally, each feature column is labeled as \"pixelX\" where X refers to the pixel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General description of the DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Look at general information about the training data\n",
    "print('\\nGeneral description of the DataFrame:')\n",
    "print(train_import.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 42,000 observations in the dataset, each having 785 features.  All data types are int64, meaning they are 64-bit integers.  The memory usage is 251.5 MB, which appears larger than other datasets I have worked with in the past.  This suggests that the time for computation may be slower than I have seen in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max number of values per training dataset feature that are NaN: 0\n",
      "\n",
      "Max number of values per test dataset feature that are NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Check to see if there are any null values in the dataset.\n",
    "print('\\nMax number of values per training dataset feature that are NaN:', train_import.isnull().sum().max())\n",
    "print('\\nMax number of values per test dataset feature that are NaN:', test_import.isnull().sum().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the max summed value of NaN values is zero, this indicates that there are zero null values in the training and test datasets and it can be assumed that both datasets are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics of the DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the descriptive statistics of the data.\n",
    "print('\\nDescriptive statistics of the DataFrame:')\n",
    "train_import.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 2: Descriptive Statistics of Train Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the number of features, Table 2 is hard to review manually.  What we can say from the snapshot shown above is that for the label feature the mean is about 4.5.  This is expected as the numbers range from 0 to 9 (confirmed by the min and max in Table 2), and this suggests that there is an even distribution of target variables.  To confirm the distribution of label values, below is a count of each value category.  This distribution is pretty similar with 5 having the minimum number of target variables and 1 having the largest number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4132\n",
      "1    4684\n",
      "2    4177\n",
      "3    4351\n",
      "4    4072\n",
      "5    3795\n",
      "6    4137\n",
      "7    4401\n",
      "8    4063\n",
      "9    4188\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Max:  1    4684\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Min:  5    3795\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Look at the distribution of digits in the train data.\n",
    "num_count = train_import['label'].value_counts().sort_index()\n",
    "print(num_count)\n",
    "print('\\nMax: ', num_count.nlargest(1))\n",
    "print('\\nMin: ', num_count.nsmallest(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test and Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data, both X and y are provided.\n",
    "X_train = train_import.drop(columns=['label']) # Drop label feature from dataset\n",
    "y_train = train_import['label']\n",
    "\n",
    "# Test data, note that no y_test exists because it is unknown.\n",
    "X_test = test_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Review the shape of the data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Digit Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some example images.  Functions were defined so that we can look at these images again in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single digit specified by specific .iloc\n",
    "def plot_digit(data):\n",
    "    image = data.values.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first example of 0 through 9\n",
    "def plot_digit_w_label(data, digit):\n",
    "    print('\\nLabeled value', digit)\n",
    "    idx_loc = data[data['label']==digit].index[0]\n",
    "    coords = data.iloc[idx_loc]\n",
    "    some_digit = coords[1:]\n",
    "    some_digit_image = some_digit.values.reshape(28, 28)\n",
    "    plt.imshow(some_digit_image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several digits\n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a single random digit\n",
    "plot_digit(X_train.loc[3600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 1: An example of a single digit from the training dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABwBJREFUeJzt3V9ozf8Dx/EfcaGtjdRCxBVXys0opUT+c2XjZqKURrlCLt1ScjFJu5WINaXU0O64sNygtEu1G0mtzUZE9r1x8VPO+3Ccc5jX43Hp1dnn7VvP76d8ds6ZMzMz8z/g3zf3Tx8AaA6xQwixQwixQwixQ4h5Tb6ef/qHxpvzoz90Z4cQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQYocQzf7KZmowPj5e3KenpytuV65c+a1rj4yMFPcTJ04U97a2torbjh07iq+dM+eH3zxMjdzZIYTYIYTYIYTYIYTYIYTYIYTYIYTn7E0wNTVV3IeGhop7T09Pcf/8+fMvn6leXr9+XdzHxsYqbkeOHCm+9uzZs8V91apVxZ3vubNDCLFDCLFDCLFDCLFDCLFDCLFDiDkzMzPNvF5TL9YsExMTxf3QoUPF/d69e/U8zj9jyZIlxf3u3bvFfc2aNRW39vb2ms40S/zwgwDc2SGE2CGE2CGE2CGE2CGE2CGER291cP/+/eK+a9euJp2E/3f16tWKW29vbxNP0nQevUEysUMIsUMIsUMIsUMIsUMIsUMIHyX9kx49elRxu3DhQhNPUl99fX3FfdmyZcX94sWLxf3Jkye/fKZ6OXPmTMVt8eLFxdd2d3fX+zh/nDs7hBA7hBA7hBA7hBA7hBA7hBA7hPB+9p+0f//+itudO3caeu3Ozs7ivmHDhpp/9rFjx4r72rVri/v79++L+/j4eMWt2rPskZGR4v47urq6ivvAwEDDrt0E3s8OycQOIcQOIcQOIcQOIcQOIcQOIbyf/Ztqv2/QyN9HuHHjRnHv6Ogo7lu3bq3ncX5JS0tLzfvOnTuLr3369Glx//r1a3EvGR0dLe7VvkZ77969NV/7T3FnhxBihxBihxBihxBihxBihxBihxDez/7N8+fPi/u6desadu2xsbHivmLFioZd+282ODhY3Ku9J/13VHuff39/f8OuXQfezw7JxA4hxA4hxA4hxA4hxA4hvMX1m1evXjXsZ7e3txf3+fPnN+zas9nGjRuLe7X/rpOTk/U8zqznzg4hxA4hxA4hxA4hxA4hxA4hxA4hPGf/ZuHChQ372evXry/uixYtati1Z7OlS5cW9927dxf3mzdv1nztBw8eFPfp6eni3traWvO1G8WdHUKIHUKIHUKIHUKIHUKIHUKIHULEfJT0u3fvivvq1auL+5s3b+p5nO/4KOnaVPta5X379jXs2uPj48X9D//uhI+ShmRihxBihxBihxBihxBihxBihxAx72f/8uVLcW/kc3QaY/ny5X/6CLOKOzuEEDuEEDuEEDuEEDuEEDuEEDuEiHnOXu1z4Xt6eor79evX63kcaDp3dgghdgghdgghdgghdgghdggR8+ht7tzy/9e2bdtW3Bv56K27u7u4Dw8PF/e/8euB62FiYqK4Hz58uGHXPn78eHFv5Fd8N4o7O4QQO4QQO4QQO4QQO4QQO4QQO4SI+crmaiYnJ4v75s2bK27Pnj2r82m+19nZWdzPnz9fcduyZUu9j1M3b9++Le6nT58u7teuXav52gsWLCjuo6OjxX3lypU1X7sJfGUzJBM7hBA7hBA7hBA7hBA7hBA7hPCc/Sc9fvy44tbb21t87cuXL+t9nO9s2rSp4tbX1/dbP7utra24f/r0qea92vvRX7x4Udx/R1dXV3EfGBho2LWbwHN2SCZ2CCF2CCF2CCF2CCF2CCF2COE5ex3cvn27uB89erS4T09P1/M4ddXR0VHcP3z4UNz/1r/brVu3ivuBAweadJKG8JwdkokdQogdQogdQogdQogdQnj01gSXLl0q7qdOnWrSSf4t1b42ub+/v+K2Z8+e4mtbWlpqOtNfwqM3SCZ2CCF2CCF2CCF2CCF2CCF2COE5exNMTU0V94MHDxb3oaGheh5n1mhtbS3ug4ODxX379u31PM5s4jk7JBM7hBA7hBA7hBA7hBA7hBA7hPCc/S/w8ePH4j48PFzcHz58WHG7fPlyTWeql5MnT1bczp07V3ztvHnzint7e3tNZwrgOTskEzuEEDuEEDuEEDuEEDuEEDuE8Jwd/j2es0MysUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUOIeU2+3g+/ShZoPHd2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CCF2CPEf8k0mCprIaswAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABZ1JREFUeJzt3b9qVFsYxuGZk6hpEgtrL8AmRRqDViJqIxKwMCmMlZ29QirRzitIJUGInX8uQC1EBMEiaBfEIlgoKTSdYJjTHTiQ/Q1mm21m3ucp87HXCuiPBS73TH8wGPSA8ffP3/4FgG6IHUKIHUKIHUKIHUJMdryff/qHg9ff64dOdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgghdgjR9Vc2Q2fOnz/fOHv58mX57NraWjlfXl7e1+/0NznZIYTYIYTYIYTYIYTYIYTYIYTYIYR7dkbWuXPnyvmbN28aZ/1+v3x22HwUOdkhhNghhNghhNghhNghhNghhNghhHt2Dq379++X87dv35bzX79+Nc6uXbtWPnv16tVyPoqc7BBC7BBC7BBC7BBC7BBC7BCiPxgMutyv08043J49e1bOl5aWyvnPnz/L+ezsbOPs9evX5bPT09Pl/JDb8/1cJzuEEDuEEDuEEDuEEDuEEDuEEDuE8IorB2pra6txdvfu3fLZYffoJ06cKOf37t1rnI34Pfq+ONkhhNghhNghhNghhNghhNghhNghhPfZaeXdu3fl/ObNm42zDx8+tNp7fX29nC8uLrZaf4R5nx2SiR1CiB1CiB1CiB1CiB1CiB1CeJ+d0qNHj8r58vJyOe/397zy7fV6vd7x48fLZy9cuFDOL126VM75Pyc7hBA7hBA7hBA7hBA7hBA7hBA7hHDPHu7r16/l/MGDBwe298LCQjl/+PDhge2dyMkOIcQOIcQOIcQOIcQOIcQOIVy9jbnv37+X84sXL5bzjx8/ttp/ZmamcXblypVWa/N7nOwQQuwQQuwQQuwQQuwQQuwQQuwQwlc2j7kvX76U85MnT7Zaf9jfn52dncbZ9PR0q71p5CubIZnYIYTYIYTYIYTYIYTYIYTYIYT32cfA9vZ24+zy5cvls23/n8X8/Hw5P3r0aKv1+XOc7BBC7BBC7BBC7BBC7BBC7BBC7BDCPfsYuHXrVuNsY2OjfLbf3/PV5/+cOXOmnL948aKcHzt2rJzTHSc7hBA7hBA7hBA7hBA7hBA7hBA7hHDPPgKq99V7vV7v06dP+1572Pvmd+7cKefu0UeHkx1CiB1CiB1CiB1CiB1CiB1CuHo7BL59+1bOl5aWyvn79+8bZ1NTU+Wzq6ur5XzYR1EzOpzsEELsEELsEELsEELsEELsEELsEMI9+yHw9OnTcv7q1at9r3369Olyfv369X2vzWhxskMIsUMIsUMIsUMIsUMIsUMIsUMI9+wdePz4cTm/fft2q/XPnj3bOFtfX2+1NuPDyQ4hxA4hxA4hxA4hxA4hxA4hxA4h+oPBoMv9Ot2sKz9+/Cjnc3Nz5fzz58+t9n/y5EnjbGFhodXajKT+Xj90skMIsUMIsUMIsUMIsUMIsUMIr7j+Ac+fPy/nba/WhtnZ2TnQ9RkPTnYIIXYIIXYIIXYIIXYIIXYIIXYI4Z79Dzhy5Eg5n5iYKOe7u7vlfHKy/mPa3Nws59DrOdkhhtghhNghhNghhNghhNghhNghhI+S7sCpU6fK+bB79pWVlXJ+48aN3/6dGGs+ShqSiR1CiB1CiB1CiB1CiB1CiB1CuGeH8eOeHZKJHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUJMdrzfnl8lCxw8JzuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuE+Bcdha0+cTQLSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABSlJREFUeJzt3S9vVFkcgGFmg6omwaFhvkM1kgASLN+BECThM5Ag8fyxyBbXoAGJhVpw0DW7ajvntr3DdGfe55H8cplDyZuTcDh3FicnJ1eA3ffXZS8A2AyxQ4TYIULsECF2iLi64c/zT//w5y1O+0U7O0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHCLFDhNghQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ8TVy17Atnj9+vXK2fv374fP3r17dzi/du3ahdb0rxs3bqycHR8fD5/9+fPnrM+e4+DgYDh/+/btcH7r1q3h/MmTJytno5/ZrrKzQ4TYIULsECF2iBA7RIgdIsQOEYuTk5NNft5GP2ydnj9/vnL29OnT4bOLxWI4n/o7mHp+zjn7jx8/Zn32nLXP/XNP/f+Eo6OjlbMdP2c/9QdnZ4cIsUOE2CFC7BAhdogQO0SIHSLcZz+j379/r5y9ePFi+Oz+/v5wfnh4eKE1bYMPHz6snL169WrW7/3gwYPhfMfP0s/Nzg4RYocIsUOE2CFC7BAhdogQO0Q4Zz+jd+/erZw9evRo+OzU+82n5tvszZs3K2dT99WXy+VwPnovPP9lZ4cIsUOE2CFC7BAhdogQO0SIHSKcs6/B58+fL3sJl2bqvfNfv35dOZt6b/zjx4+H87nfa19jZ4cIsUOE2CFC7BAhdogQO0Q4evvHp0+fhvPR8drUFdddNnXs+OXLl5Wze/fuDZ+dmnM+dnaIEDtEiB0ixA4RYocIsUOE2CHCOfsZuU55uocPHw7no2ust2/fHj67t7d3oTVxOjs7RIgdIsQOEWKHCLFDhNghQuwQ4Zz9H1Nfm3x0dLShlWyX0X31K1emv5aZzbGzQ4TYIULsECF2iBA7RIgdIsQOEc7Zz6h6n/3g4GA4n/ra5ZH9/f0LP8v52dkhQuwQIXaIEDtEiB0ixA4RYocI5+wMTX3/+tR99fv376+cTb1DgPWys0OE2CFC7BAhdogQO0SIHSIcvTF0eHg4nE9dcb1z5846l8MMdnaIEDtEiB0ixA4RYocIsUOE2CHCOTtDc6+4LpfLdS6HGezsECF2iBA7RIgdIsQOEWKHCLFDhHP2uI8fP86az/nKZjbLzg4RYocIsUOE2CFC7BAhdogQO0Q4Z2do6r4628PODhFihwixQ4TYIULsECF2iHD0xtDUFVZXXLeHnR0ixA4RYocIsUOE2CFC7BAhdohwzs7Q1BXXmzdvzpqzOXZ2iBA7RIgdIsQOEWKHCLFDhNghwjl73MuXL4fzqfvqz549G8739vbOvSb+DDs7RIgdIsQOEWKHCLFDhNghQuwQsdjwe7+9ZPx/5vr168P58fHxcP7r1691Lof1OPUlBHZ2iBA7RIgdIsQOEWKHCLFDhNghwn32Hff9+/fh/Nu3b8P51Hvj2R52dogQO0SIHSLEDhFihwixQ4Sjtx03dXQ2NV8ul+tcDpfIzg4RYocIsUOE2CFC7BAhdogQO0R4lTTsHq+ShjKxQ4TYIULsECF2iBA7RIgdIjZ9n917ieGS2NkhQuwQIXaIEDtEiB0ixA4RYocIsUOE2CFC7BAhdogQO0SIHSLEDhFihwixQ4TYIULsECF2iBA7RIgdIsQOEWKHiL8BA8+n2i9pf1wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAB1xJREFUeJzt3T1olfcfxuHkj1CwKFJRqVAUSjqoQ/BlbBfrUEScBSmC7WAp6i4OASmoOAipyRCXdnAoBQdfwSBR1EWqQ4hQRGoGEd8pFRsV08X/UPR8n9aTk1jv6xp785w8gXx4oD/POd2Tk5NdwLvvfzN9A8D0EDuEEDuEEDuEEDuEmDXNP8//+ofO637df/RkhxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxBihxCzZvoG6KyJiYlyf/jwYVuvf/LkyXLfunVrW6/fjsnJyZbb+vXry2v37NlT7r29vW90TzPJkx1CiB1CiB1CiB1CiB1CiB1CdFfHEx0wrT8sxfj4eMvtq6++Kq8dHh5u62c3/f10d3e39frtqO6t6b4WL15c7hcvXiz3jz76qNw77LW/nCc7hBA7hBA7hBA7hBA7hBA7hBA7hPAW1/+AX3/9tdz379/fcmv3HH0mNZ119/f3l/vOnTtbbtW/Tejq6uq6detWuQ8NDZV7X19fuc8ET3YIIXYIIXYIIXYIIXYIIXYIIXYI4Zz9LfDTTz+V+7ffflvu9+7dm8rbeWt8+OGH5f7555+X+/Lly1tuTefsTWbPnt3W9TPBkx1CiB1CiB1CiB1CiB1CiB1CiB1COGefBqOjo+X+9ddfl/vvv/9e7jP52eydNDY2Vu4HDhwo97t3707l7fzNzZs3O/baneLJDiHEDiHEDiHEDiHEDiHEDiHEDiF8P/sUmJiYKPdVq1aVe9N58kx+B/rChQvLvel93ceOHWu5LVu2rLx2cHCw3L/55ptyb+f72Xt7e8v99OnT5b5gwYJy7zDfzw7JxA4hxA4hxA4hxA4hxA4hvMV1Cjx48KDcHz9+XO7tHp21c/0nn3xS7hcuXCj3Dz744I1/9o0bN8r94MGD5d7O771kyZJyP3ToULnP8NHaG/FkhxBihxBihxBihxBihxBihxBihxDe4joNDh8+XO5NX8nc9Bbads6bjx49Wu4bNmwo96Z7GxkZabnt2rWrvPaXX34p9yYbN25suX3//ffltU1fF/2W8xZXSCZ2CCF2CCF2CCF2CCF2CCF2COGc/S3Q9FHSK1asKPd2ztnnzZtX7t999125X7p0qdx//PHHf31P//fxxx+X+/bt28u96d8vvMOcs0MysUMIsUMIsUMIsUMIsUMIsUMI5+z/AU3nxQMDA9N0J69q+vtZtGhRy2337t3ltZs3by73uXPnlnsw5+yQTOwQQuwQQuwQQuwQQuwQQuwQwjn7f8Dt27fLffHixdN0J69q+vvZsmVLy21wcLC89r333nuTW8I5O2QTO4QQO4QQO4QQO4QQO4SYNdM3QFfX6OhouZ84caLcq4+SnjNnTnnt8+fPy/3Jkyfl3uTUqVMtt/Hx8fLanp6etn42f+fJDiHEDiHEDiHEDiHEDiHEDiHEDiGcs0+B+/fvl/uOHTvK/eeffy73iYmJcl+7dm3Lbe/eveW1V65cKfemj7Fuurc7d+603H777bfyWufsU8uTHUKIHUKIHUKIHUKIHUKIHUKIHUI4Z58C58+fL/czZ86U+9OnT8t91apV5d7X19dyW7lyZXlt0379+vVybzrHr1y+fLnc161b98avzas82SGE2CGE2CGE2CGE2CGE2CGE2CGEc/Z/qPps902bNpXXNp2jr1mzptyHh4fL/f333y/3dsyfP79jr7169eqOvTav8mSHEGKHEGKHEGKHEGKHEGKHEI7e/qF9+/a13Jo+Tvmzzz4r9+PHj5d7J4/WmoyMjJT75OTkNN0J7fJkhxBihxBihxBihxBihxBihxBihxDO2V969uxZuT969Kjl1t3dXV77xRdflHvTOXrTvY2NjZV75Ycffij3s2fPlnvT7960M3082SGE2CGE2CGE2CGE2CGE2CGE2CGEc/aXXrx4Ue5//vnnG792f39/uTedZTe9X/7cuXP/+p6my5w5c1punfyYal7lyQ4hxA4hxA4hxA4hxA4hxA4hxA4hnLO/9Pz583JftmxZy+3atWvltbdu3Wprb/ps9pl8z/jQ0FC5f/rppy23np6eqb4dCp7sEELsEELsEELsEELsEELsEELsEKJ7mr9f+538Mu+rV6+W+5EjR8p9YGCg3P/4449yX7RoUcvtyy+/LK9tsm3btnJfunRpW69PR7z2H154skMIsUMIsUMIsUMIsUMIsUMIR2/w7nH0BsnEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiHEDiGm+yubZ+67hSGcJzuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuEEDuE+Au6dlYbDaK1VAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labeled value 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABolJREFUeJzt3U+IjXscx/EzNwoZUiQr2aLUWFlMaVJWimZBFqxmZcOWBY1mIws7KzUWsvAnI2zEStgKsdEUKxomGqFRc1d3dZ3vc52ZOeaez+u1vJ+ec47bfffU/TnP6Zubm2sBve+vP/0BgO4QO4QQO4QQO4QQO4RY1uX387/+YfH1/eofurNDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDCLFDiGV/+gOwtH3+/LncJycny/3y5cttt5cvX5bXPn78uNxHRkbK/fjx4223zZs3l9f2Ind2CCF2CCF2CCF2CCF2CCF2CNE3NzfXzffr6pvR7MaNG+U+Ojpa7s+fPy/3vr6+3/5MC2VwcLDtNjExUV67du3ahf443fTLf+nu7BBC7BBC7BBC7BBC7BBC7BBC7BDCOXsPmJ2dbbsdPXq0vPbu3bvlPjMzU+5N//1U5+zDw8PltStWrCj3K1eulHvl/Pnz5X7ixImOX3sJcM4OycQOIcQOIcQOIcQOIcQOIcQOITxKegmozslbrVbr6dOn5V6dV3/8+LGjz/SPVatWlfvJkyfLfd++fW23rVu3ltc2ffbr16+X+48fP9pu3759K6/tRe7sEELsEELsEELsEELsEELsEELsEML32ZeAW7dulXvT974rTefk+/fvL/em73UPDAz89mf6r5r+/sH4+Hi59/f3t92a/txN36Vf4nyfHZKJHUKIHUKIHUKIHUKIHUKIHUL4PnsXXLx4sdxPnz49r9fftm1b263p++aHDh2a13vPx71798r97Nmz5f7q1atyf/ToUdvtf36O3hF3dgghdgghdgghdgghdgghdgjh6K0Lmr7C2vTI5OpordVqtR48eNB227BhQ3ntz58/y/379+/l/u7du3IfGhpqu3369Km8tumzNfn69eu8ru817uwQQuwQQuwQQuwQQuwQQuwQQuwQwjl7Fzx58mRe1zeddZ86darj13779m25379/v9ybHkXe1/fLpxr/J8uXLy/33bt3l/uWLVs6fu9e5M4OIcQOIcQOIcQOIcQOIcQOIcQOIfxkcxfs2LGj3F+8eNGlT7LwFvOcfdeuXeVePSo6nJ9shmRihxBihxBihxBihxBihxBihxDO2btgenq63F+/fl3u165dK/fqHP/Zs2fltQcOHCj3qampch8eHi736px9+/bt5bXV8/BbrVZr/fr15R7MOTskEzuEEDuEEDuEEDuEEDuEEDuE8Nz4Lli3bl25N31vu2mfj6bfMD98+HC5N/09jY0bN7bdmp537xx9YbmzQwixQwixQwixQwixQwixQwhHbz1uZmam3C9cuFDud+7cKfeVK1eW+82bN9tui3mkyL+5s0MIsUMIsUMIsUMIsUMIsUMIsUMI5+w9bmxsrNzPnTs3r9cfHx8vd2fpS4c7O4QQO4QQO4QQO4QQO4QQO4QQO4Twk809YGJiou128ODB8trZ2dlyb3qc8/v378udP8JPNkMysUMIsUMIsUMIsUMIsUMIsUMI5+w9YNOmTW23Dx8+lNfu3Lmz3B8+fFjuq1evLnf+COfskEzsEELsEELsEELsEELsEMKjpJeAqampch8ZGSn36enpjt97aGio3B2t9Q53dgghdgghdgghdgghdgghdgghdgjhnH0JuHr1arnfvn2749c+cuRIuY+Ojnb82vy/uLNDCLFDCLFDCLFDCLFDCLFDCLFDCI+S7oLJycly37t3b7m/efOm4/ceHBws94GBgXI/c+ZMua9Zs+Z3PxKLz6OkIZnYIYTYIYTYIYTYIYTYIYTYIYTvs3fBpUuXyn0+5+hNvnz5Uu579uwpd+fovcOdHUKIHUKIHUKIHUKIHUKIHUKIHUI4Z+8Bx44da7uNjY2V1/b39y/0x2GJcmeHEGKHEGKHEGKHEGKHEGKHEB4lDb3Ho6QhmdghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghRLcfJf3L79kCi8+dHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUKIHUL8Dei8FN8O/K4tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an example of each digit\n",
    "for num in range(0,10):\n",
    "    plot_digit_w_label(train_import,num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 2: Examples of each digit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly plot a selection of digits.\n",
    "plt.figure(figsize=(9,9))\n",
    "example_images = np.r_[X_train[:12000:600], X_train[13000:30600:600], X_train[30600:60000:590]]\n",
    "plot_digits(example_images, images_per_row=10)\n",
    "#save_fig(\"more_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 3: More examples of the digit images contained in the training dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No transformations were completed for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms typically require input data to be normalized to help create efficiencies in the time it takes to train the data.  This is because when using Gradient Descent, the algorithm is able to train the data a lot faster with making incrimental steps between 0 and 1 than it can on a larger scale.  This also puts all input vectors on a common scale for use in the algorithm.\n",
    "\n",
    "While there are several ways to do this, I have selected using the MinMaxScaler() from Scikit-Learn.  Note that I have fit the scaler to the training dataset and then transformed the training and test dataset separately.  This is to prevent the model from infering information about the test data prior to actually seeing the data.\n",
    "\n",
    "It is interesting to note that while it perfectly scales the training data as expected, the test data has at least one datapoint that falls very far outside of the 0-1 fitted range with a value of 226.  I am assuming this is due to one (or potentially a few) dark pixel(s) that exists in probably one test dataset image in a position where the training dataset only has very light pixels.  I would guess it is most likely an outlier in the test dataset.\n",
    "\n",
    "Other methods to use are the StandardScaler() or simply dividing each pixel by the max value of 255.  I chose not to use the StandardScaler() because it resulted in some large values in both the training and test datasets and was not providing very good results on an initial run of a deep neural network.  The approach of dividing the pixels by 255 was a simple and easy approach, but I chose to use the MinMaxScaler instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (42000, 784)\n",
      "Dataframe minimum of per-feature values before scaling:\n",
      " 0\n",
      "Dataframe maximum of per-feature values before scaling:\n",
      " 255\n",
      "Dataframe minimum of per-feature values after scaling:\n",
      " 0.0\n",
      "Dataframe maximum of per-feature values after scaling:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Transform data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "# Print dataset properties before and after scaling\n",
    "print(\"Transformed shape: {}\".format(X_train_scaled.shape))\n",
    "print(\"Dataframe minimum of per-feature values before scaling:\\n {}\".format((X_train.min()).min()))\n",
    "print(\"Dataframe maximum of per-feature values before scaling:\\n {}\".format((X_train.max()).max()))\n",
    "print(\"Dataframe minimum of per-feature values after scaling:\\n {}\".format((X_train_scaled.min()).min()))\n",
    "print(\"Dataframe maximum of per-feature values after scaling:\\n {}\".format((X_train_scaled.max()).max()))\n",
    "#print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\n",
    "#print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\n",
    "#print(\"per-feature minimum after scaling:\\n {}\".format(X_train_scaled.min(axis=0)))\n",
    "#print(\"per-feature maximum after scaling:\\n {}\".format(X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MinMaxScaler(copy=True, feature_range=(0, 1))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the parameters of the scaler\n",
    "scaler.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (28000, 784)\n",
      "Dataframe minimum of per-feature values after scaling:\n",
      " 0\n",
      "Dataframe maximum of per-feature values after scaling:\n",
      " 255\n",
      "Dataframe minimum of per-feature values after scaling:\n",
      " 0.0\n",
      "Dataframe maximum of per-feature values after scaling:\n",
      " 226.0\n"
     ]
    }
   ],
   "source": [
    "# Transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Transformed shape: {}\".format(X_test_scaled.shape))\n",
    "# Print test data properties before and after scaling\n",
    "print(\"Dataframe minimum of per-feature values after scaling:\\n {}\".format((X_test.min()).min()))\n",
    "print(\"Dataframe maximum of per-feature values after scaling:\\n {}\".format((X_test.max()).max()))\n",
    "print(\"Dataframe minimum of per-feature values after scaling:\\n {}\".format((X_test_scaled.min()).min()))\n",
    "print(\"Dataframe maximum of per-feature values after scaling:\\n {}\".format(X_test_scaled.max()))\n",
    "#print(\"per-feature minimum after scaling:\\n{}\".format(X_test_scaled.min(axis=0)))\n",
    "#print(\"per-feature maximum after scaling:\\n{}\".format(X_test_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Validation Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create use cross validation to train a model, a validation dataset must be created from the training set.  A validation set is a sub dataset made up of observations from the training set, including the features and the target response variable.  This validation set is not used during the training of the model, but is used to validate the results of the model after training by predicting the target response of the unseen validation data and then comparing those predictions to the actual validation target response.  This allows the researcher to evalute the model's ability to generalize to new observations.\n",
    "\n",
    "To optimize the split of the existing training data set into a new training and validaiton set, a several split sizes will be looped through a simple neural network.  This split size yielding the best results on this simple network will be assumed to represent the optimal split for future neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Optimal Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sizes\n",
    "test_size = [0.05,0.1,0.15,0.2,0.25,0.3] # validation set sizes to try, where the size is a ratio\n",
    "                                         # of the training set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to record the results of each iteration\n",
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "validation_performance_results = []\n",
    "processing_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.05\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpl5cmor3l\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\tmpl5cmor3l', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EE2FA9F470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "\n",
      "Processing time (seconds): 71.529354\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.970476\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.1\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpsgibv4jt\n",
      "\n",
      "Processing time (seconds): 64.895221\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.973571\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.15\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpjgkh0irm\n",
      "\n",
      "Processing time (seconds): 61.044106\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.973810\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.2\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp7st37luq\n",
      "\n",
      "Processing time (seconds): 57.973283\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977143\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.25\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpjfrc_0xt\n",
      "\n",
      "Processing time (seconds): 54.685335\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.974667\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Validation Dataset Size Ratio to Training Set: 0.3\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpdqk9z0q4\n",
      "\n",
      "Processing time (seconds): 51.519984\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975397\n"
     ]
    }
   ],
   "source": [
    "# Create a loop to go through and evaluate a basic model based on several different validation set sizes.\n",
    "for size in test_size:\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nValidation Dataset Size Ratio to Training Set:', size)\n",
    "    \n",
    "    start_time = time.clock() # start timer to evaluate how long it takes to train this base model\n",
    "    \n",
    "    X = X_train_scaled # define the X variables\n",
    "    y = y_train # define the response variable\n",
    "\n",
    "    \n",
    "    X_train_eval, X_valid_eval, y_train_eval, y_valid_eval = train_test_split(X, y, test_size=size, \\\n",
    "                                                                              random_state=RANDOM_SEED) # split data\n",
    "                                                                                                        # and return arrays\n",
    "    X_train_eval = X_train_eval.astype(np.float32).reshape(-1, 28*28) # turn to float and resize \n",
    "    X_valid_eval = X_valid_eval.astype(np.float32).reshape(-1, 28*28) # turn to float and resize \n",
    "    y_train_eval = y_train_eval.astype(np.int32).values # turn to int\n",
    "    y_valid_eval = y_valid_eval.astype(np.int32).values # turn to int\n",
    "    \n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    # Create the model\n",
    "    feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "    dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
    "                                         feature_columns=feature_cols) # create DNN classifier\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                            # to increase usability when uploaded to GitHub.\n",
    "\n",
    "    # Train the model\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train_eval}, y=y_train_eval, num_epochs=40, batch_size=50, shuffle=True)\n",
    "    dnn_clf.train(input_fn=input_fn)\n",
    "    \n",
    "    end_time = time.clock() # end timer\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime) # print process time to train model      \n",
    "    processing_time.append(runtime) # append process time results to list for comparison table\n",
    " \n",
    "    # Use training and validation data to check model results\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train_eval}, y=y_train_eval, shuffle=False)\n",
    "    train_eval_results = dnn_clf.evaluate(input_fn=train_input_fn) # training results\n",
    "    \n",
    "    valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_valid_eval}, y=y_valid_eval, shuffle=False)\n",
    "    valid_eval_results = dnn_clf.evaluate(input_fn=valid_input_fn) # validation results\n",
    "      \n",
    "    \n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = train_eval_results['accuracy']\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance) # append results to list for comparison table\n",
    "\n",
    "    # mean accuracy of prediction in test set\n",
    "    validation_performance = valid_eval_results['accuracy']\n",
    "    print(\"\\nValidation set accuracy: %f\" % validation_performance)\n",
    "    validation_performance_results.append(validation_performance) # append results to list for comparison table\n",
    "                \n",
    "    index_for_method += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Dataset Size Ratio to Training Dataset: Tensorflow Deep Neural Networks\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Dataset Ratio</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>71.529354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>64.895221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>61.044106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>57.973283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>54.685335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>51.519984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validation Dataset Ratio  Processing Time  Training Set Accuracy  \\\n",
       "0                      0.05        71.529354                    1.0   \n",
       "1                      0.10        64.895221                    1.0   \n",
       "2                      0.15        61.044106                    1.0   \n",
       "3                      0.20        57.973283                    1.0   \n",
       "4                      0.25        54.685335                    1.0   \n",
       "5                      0.30        51.519984                    1.0   \n",
       "\n",
       "   Validation Set Accuracy  \n",
       "0                 0.970476  \n",
       "1                 0.973571  \n",
       "2                 0.973810  \n",
       "3                 0.977143  \n",
       "4                 0.974667  \n",
       "5                 0.975397  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to display results of experiement\n",
    "results = pd.DataFrame(OrderedDict([('Validation Dataset Ratio', test_size),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Validation Set Accuracy', validation_performance_results)]))\n",
    "\n",
    "print('\\nValidation Dataset Size Ratio to Training Dataset: Tensorflow Deep Neural Networks\\n')\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 3: Validation Dataset Size Ratio to Training Dataset: Tensorflow Deep Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results in Table 3 of this experiment, we can see that the validation dataset size of 20% of the entire training dataset may be optimal.  This may be trivial, as there does not seem to be a significant difference in the validation dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Validation Test Set for Modeling Based on Optimial Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from the previous experiement, an optimal training/validation dataset split can now be created.  Below, a training set and validation set are created to use in the development of models. Note that reshaping the data into an array with float data types is necessary for feeding it into Tensorflow.  Below I take the normalized data and break it into a test and validation set for use in training a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_scaled # define the training X variables\n",
    "y = y_train # define the training response variable\n",
    "\n",
    "opt_test_size = 0.2 # optimal test size from previous experiment\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=opt_test_size, random_state=RANDOM_SEED) # split data\n",
    "                                                                                                     # and return arrays\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) # turn to float and resize \n",
    "X_valid = X_valid.astype(np.float32).reshape(-1, 28*28) # turn to float and resize \n",
    "y_train = y_train.astype(np.int32).values # turn to int \n",
    "y_valid = y_valid.astype(np.int32).values # turn to int \n",
    "\n",
    "X_test = X_test_scaled # define the test X variable (response variable unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(33600,)\n",
      "(8400, 784)\n",
      "(8400,)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of all arrays\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that good normalized training and validation datasets have been created to use in Tensorflow deep neural networks, it was decided the data should be pickled so that it can be saved for use again at a later point if needed.  This is valuable because all of the previous code can be avoided in future testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Run complete. data objects sent to binary file  mnist_data.pickle\n"
     ]
    }
   ],
   "source": [
    "# Define collection of objects to export as binary file using pickle.\n",
    "data = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_valid': X_valid,\n",
    "    'y_valid': y_valid,\n",
    "    'X_test': X_test}\n",
    "\n",
    "# Write to binary file\n",
    "with open('mnist_data_GitHub_Version.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('\\n Run complete. data objects sent to binary file  mnist_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract objects from the dictionary object data\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train'] \n",
    "X_valid = data['X_valid'] \n",
    "y_valid = data['y_valid'] \n",
    "X_test = data['X_test'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow will be used to develop a deep neural network (DNN) for the MNIST data set.  A neural network is simply a composite function that accepts inputs and calculates one or more outputs.  Where a DNN differs from other machine learning models is that the structure of the composite function is modeled after the human brain.  The basic concept is that the model accepts inputs to the model, and then passes these inputs through a series of interconnected nodes.  Using response variables to test which nodes were activiated with any particular combination of inputs, and then adjusting each node's activiation criteria to better fit the anticipated response is what makes these DNNs so powerful when it comes to learning.\n",
    "\n",
    "Let's break down the structure of DNN a bit more.  A DNN model starts out with a defined data input layer that has an individual input node for each input. This input layer is then fully connected to at least one hidden layer, which is a separate layer of nodes, each of which is connected to every single node in the input layer.  Additionally, each node in this hidden layer is connected to each node in the following layer.  Each additional hidden layer follows this same format so that all nodes in a layer are connected to all nodes in the previous layer and all nodes in the following layer.  Last, an output layer is created to produce a result from the DNN.  As you may guess, this layer had individual nodes for each possible output that are connected to each node in the previous layer.  Figure 4 from Suryansh (2018) shows a graphical represenation of a neural network.  This figure clearly shows the input layer that has 8 separate inputs, 3 hidden layers each having 9 nodes, and the output layer that has 4 possible responses.\n",
    "\n",
    "References: Suryansh S. (2018, April 7). Neural Networks: All YOU Need to Know. Retrieved from https://towardsdatascience.com/nns-aynk-c34efe37f15a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](DNNs_MNIST_GLAWSON_Fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 4: Example of a Deep Neural Network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting to deep into the mathematics behind DNNs, the general idea is that each hidden layer node has a connection weight that tells a node when to activate.  In training, the network uses these weights to activate specific neuron pathways that result in a specific predicted output.  This predicted output is then compared to a known output, and the model generates a bias on how it \"thinks\" it should update the weights to better represent the actual known outputs.  It then back propogates these bias values, slightly changing the connection weights.  A series of iterations of backpropogation can be complete to let the DNN learn over several groupings of data what connection weights best represent the desired output.\n",
    "\n",
    "While Tensorflow can be used on its own, I have chosen to use the Scikit-Learn API that uses Tensorflow in the background to help streamline the development and training of the models.  While it appears this method is a bit more limited than building the graphs and models manually using Tensorflow, this may not be a bad thing as I am only looking to tweak a few of the many hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Tensorflow Neural Network Using Scikit-Learn\n",
    "### Inspect How Layers and Nodes Impact Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent of this model is to create a factoral design to compare how different numbers of layers and nodes will impact the model.  The layer, also called a hidden layer, can be visualized as a mathematical way to begin breaking down the input data to look for patterns.  When more layers are added, it can be thought of as progressively combining prevously identified patterns and looking for new, more complex patterns or combinations of patterns.  For example, if the first hidden layer identified edges like straight lines of dark pixels in the images that are fed into the model, the second hidden layer may begin to look at patterns of how these edges come together to make shapes such as circles or curved lines.  Nodes or neurons are the point where a specific pattern is consistantly found, and when found in the future, this neuron will activate.  Activiation of a specific neuron causes a chain reaction of activiations in connected neurons in following layers.  Each time a specific pattern is found during training, the weights associated with the neuron connections is learned and reinforced so that future recognition of the same pattern will activate the same chain of neurons, theoretically resulting in an accurate output prediction.\n",
    "\n",
    "The number of layers in this experiment will include 2, 3, and 5.  These values were selected so allow for the model to increase in it's complexity as more layers are added in.  The number of nodes in each layer ranges from 100 nodes to 600 nodes, which were selected arbitrarily to span across a wide range that stayed between the number of input nodes and the number of output nodes.  The type of node structure in each layer was also tested to determine if a constant number of nodes in every layer (documented as a \"Constant\" layer) would perform better than a design where each layer has a decreasing number of nodes (documented as a \"Funnel\" layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create names for each iteration of the model\n",
    "names = ['2-Layers-300-Node-Max-per-Layer-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel',\n",
    "         '2-Layers-100-Node-Max-per-Layer-Constant',\n",
    "         '2-Layers-300-Node-Max-per-Layer-Constant',\n",
    "         '3-Layers-300-Node-Max-per-Layer-Funnel',\n",
    "         '3-Layers-600-Node-Max-per-Layer-Funnel',\n",
    "         '3-Layers-100-Node-Max-per-Layer-Constant',\n",
    "         '3-Layers-300-Node-Max-per-Layer-Constant',\n",
    "         '5-Layers-300-Node-Max-per-Layer-Funnel',\n",
    "         '5-Layers-600-Node-Max-per-Layer-Funnel',\n",
    "         '5-Layers-100-Node-Max-per-Layer-Constant',\n",
    "         '5-Layers-300-Node-Max-per-Layer-Constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers for each iteration of the model\n",
    "Layers = [2, 2, 2, 2, 3, 3, 3, 3, 5, 5, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of nodes for each iteration of the model.  \n",
    "# This is just informational for the comparison table.\n",
    "max_nodes_per_layer = [300, 600, 100, 300, 300, 600, 100, 300, 300, 600, 100, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of layers and number of nodes per layer for each iteration of the model.\n",
    "layer1 = [300,100]\n",
    "layer2 = [600,300]\n",
    "layer3 = [100,100]\n",
    "layer4 = [300,300]\n",
    "layer5 = [300,200,100]\n",
    "layer6 = [600,300,100]\n",
    "layer7 = [100,100,100]\n",
    "layer8 = [300,300,300]\n",
    "layer9 = [300,250,200,150,100]\n",
    "layer10 = [600,500,400,300,200]\n",
    "layer11 = [100,100,100,100,100]\n",
    "layer12 = [300,300,300,300,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[300, 100],\n",
       " [600, 300],\n",
       " [100, 100],\n",
       " [300, 300],\n",
       " [300, 200, 100],\n",
       " [600, 300, 100],\n",
       " [100, 100, 100],\n",
       " [300, 300, 300],\n",
       " [300, 250, 200, 150, 100],\n",
       " [600, 500, 400, 300, 200],\n",
       " [100, 100, 100, 100, 100],\n",
       " [300, 300, 300, 300, 300]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the layers to use in each iteration\n",
    "hidden_unit_items = [layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8, layer9, layer10, layer11, layer12]\n",
    "type(hidden_unit_items)\n",
    "hidden_unit_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to hold the results of each iteration.\n",
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "validation_performance_results = []\n",
    "processing_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-300-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [300, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmphead9959\n",
      "\n",
      "Processing time (seconds): 57.708598\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975595\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [600, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpil14l2ke\n",
      "\n",
      "Processing time (seconds): 121.792811\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977381\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-100-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [100, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp3frwg_p2\n",
      "\n",
      "Processing time (seconds): 40.963498\n",
      "\n",
      "Training set accuracy: 0.999970\n",
      "\n",
      "Validation set accuracy: 0.972738\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-300-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [300, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmptgdncdh3\n",
      "\n",
      "Processing time (seconds): 67.497696\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.973214\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 3-Layers-300-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [300, 200, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpkg4dn1_g\n",
      "\n",
      "Processing time (seconds): 69.825244\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975595\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 3-Layers-600-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [600, 300, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpxfgo94uv\n",
      "\n",
      "Processing time (seconds): 128.524423\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.974762\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 3-Layers-100-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [100, 100, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp96e0qi1_\n",
      "\n",
      "Processing time (seconds): 46.491012\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.969643\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 3-Layers-300-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [300, 300, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmprtyn8kuz\n",
      "\n",
      "Processing time (seconds): 84.511638\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.972619\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 5-Layers-300-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [300, 250, 200, 150, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp033fp4j3\n",
      "\n",
      "Processing time (seconds): 92.978005\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975238\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 5-Layers-600-Node-Max-per-Layer-Funnel\n",
      "\n",
      "  Specification of method: [600, 500, 400, 300, 200]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmppl03jlgx\n",
      "\n",
      "Processing time (seconds): 222.417990\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.970238\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 5-Layers-100-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [100, 100, 100, 100, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpwq6xlhsr\n",
      "\n",
      "Processing time (seconds): 56.169789\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.969643\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 5-Layers-300-Node-Max-per-Layer-Constant\n",
      "\n",
      "  Specification of method: [300, 300, 300, 300, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp1yq6jahi\n",
      "\n",
      "Processing time (seconds): 121.358784\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.969881\n"
     ]
    }
   ],
   "source": [
    "for name, unit in zip(names, hidden_unit_items):\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nMethod:', name)\n",
    "    print('\\n  Specification of method:', unit)\n",
    "    \n",
    "    start_time = time.clock() # start timer to evaluate how long it takes to train this base model\n",
    "    \n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    \n",
    "    # Create the model\n",
    "    feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "    dnn_clf = tf.estimator.DNNClassifier(hidden_units=unit, n_classes=10,\n",
    "                                         feature_columns=feature_cols) # create DNN classifier\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                        # to increase usability when uploaded to GitHub.\n",
    "            \n",
    "    # Train the model\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "    dnn_clf.train(input_fn=input_fn)\n",
    "    \n",
    "    end_time = time.clock() # end timer\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime)  # print process time to train model        \n",
    "    processing_time.append(runtime) # append process time results to list for comparison table\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "    train_eval_results = dnn_clf.evaluate(input_fn=train_input_fn) # training results\n",
    "    \n",
    "    valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_valid}, y=y_valid, shuffle=False)\n",
    "    valid_eval_results = dnn_clf.evaluate(input_fn=valid_input_fn) # validation results\n",
    "        \n",
    "    \n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = train_eval_results['accuracy']\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance) # append results to list for comparison table\n",
    "\n",
    "    # mean accuracy of prediction in validation set\n",
    "    validation_performance = valid_eval_results['accuracy']\n",
    "    print(\"\\nValidation set accuracy: %f\" % validation_performance)\n",
    "    validation_performance_results.append(validation_performance) # append results to list for comparison table\n",
    "                \n",
    "    index_for_method += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark Experiment: Tensorflow Deep Neural Networks\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Max Nodes per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-Layers-300-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>57.708598</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.975595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>121.792811</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.977381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-Layers-100-Node-Max-per-Layer-Constant</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>40.963498</td>\n",
       "      <td>0.99997</td>\n",
       "      <td>0.972738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Layers-300-Node-Max-per-Layer-Constant</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>67.497696</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.973214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-Layers-300-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>69.825244</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.975595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-Layers-600-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "      <td>128.524423</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.974762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-Layers-100-Node-Max-per-Layer-Constant</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>46.491012</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.969643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-Layers-300-Node-Max-per-Layer-Constant</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>84.511638</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.972619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-Layers-300-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>92.978005</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.975238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5-Layers-600-Node-Max-per-Layer-Funnel</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>222.417990</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.970238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5-Layers-100-Node-Max-per-Layer-Constant</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>56.169789</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.969643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5-Layers-300-Node-Max-per-Layer-Constant</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>121.358784</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.969881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Method Name  Layers  Max Nodes per Layer  \\\n",
       "0     2-Layers-300-Node-Max-per-Layer-Funnel       2                  300   \n",
       "1     2-Layers-600-Node-Max-per-Layer-Funnel       2                  600   \n",
       "2   2-Layers-100-Node-Max-per-Layer-Constant       2                  100   \n",
       "3   2-Layers-300-Node-Max-per-Layer-Constant       2                  300   \n",
       "4     3-Layers-300-Node-Max-per-Layer-Funnel       3                  300   \n",
       "5     3-Layers-600-Node-Max-per-Layer-Funnel       3                  600   \n",
       "6   3-Layers-100-Node-Max-per-Layer-Constant       3                  100   \n",
       "7   3-Layers-300-Node-Max-per-Layer-Constant       3                  300   \n",
       "8     5-Layers-300-Node-Max-per-Layer-Funnel       5                  300   \n",
       "9     5-Layers-600-Node-Max-per-Layer-Funnel       5                  600   \n",
       "10  5-Layers-100-Node-Max-per-Layer-Constant       5                  100   \n",
       "11  5-Layers-300-Node-Max-per-Layer-Constant       5                  300   \n",
       "\n",
       "    Processing Time  Training Set Accuracy  Validation Set Accuracy  \n",
       "0         57.708598                1.00000                 0.975595  \n",
       "1        121.792811                1.00000                 0.977381  \n",
       "2         40.963498                0.99997                 0.972738  \n",
       "3         67.497696                1.00000                 0.973214  \n",
       "4         69.825244                1.00000                 0.975595  \n",
       "5        128.524423                1.00000                 0.974762  \n",
       "6         46.491012                1.00000                 0.969643  \n",
       "7         84.511638                1.00000                 0.972619  \n",
       "8         92.978005                1.00000                 0.975238  \n",
       "9        222.417990                1.00000                 0.970238  \n",
       "10        56.169789                1.00000                 0.969643  \n",
       "11       121.358784                1.00000                 0.969881  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to display results of this experiment\n",
    "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
    "                        ('Layers', Layers),\n",
    "                        ('Max Nodes per Layer', max_nodes_per_layer),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Validation Set Accuracy', validation_performance_results)]))\n",
    "\n",
    "print('\\nBenchmark Experiment: Tensorflow Deep Neural Networks\\n')\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 5: Benchmark Experiment: Tensorflow Deep Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment a loop was used to try several different combinations of number of layers and nodes to find the opitmal structure.  Table 4 suggests that two layers in the deep neural network (DNN) provides the best accuracy when using the validation data as the decision factor, as all four tests with two layers resulted in strong validation scores typically 0.970 or greater. There is no strong reason to increase the number of layers any further as the three layer and five layer models perform slighly worse and can begin to take more time to train.  Additionally, the larger number of nodes appears to be beneficial, as the model with 2 layers and 600 node maximum per layer edges out the model with 2 layers and 300 node maximum per layer.  Last, the funnel approach to layers appears to provide the best model predictions.  While slightly on the longer side of training time (but certainly not the maximum model training time), the 2-Layers-600-Node-Max-per_Layer-Funnel model appears to be the best predictor when using accuracy of the validation set predictions as an indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Tensorflow Neural Network Using Scikit-Learn\n",
    "### Fine Tune Number of Layers and Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from the previous experiements, this model will continue to fine tune the DNN model.  Specifically, a 2-layer DNN will be developed to optimize the validation predictions.  The step in the node funnel size will be evaluated further to find an optimal model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create names for each iteration of the model\n",
    "names = ['2-Layers-600-Node-Max-per-Layer-50-Step-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-100-Step-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-200-Step-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-300-Step-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-400-Step-Funnel',\n",
    "         '2-Layers-600-Node-Max-per-Layer-500-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-50-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-100-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-200-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-300-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-400-Step-Funnel',\n",
    "         '2-Layers-700-Node-Max-per-Layer-500-Step-Funnel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers for each iteration of the model\n",
    "Layers = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of nodes for each iteration of the model.  \n",
    "# This is just informational for the comparison table.\n",
    "max_nodes_per_layer = [600, 600, 600, 600, 600, 600, 700, 700, 700, 700, 700, 700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of layers and number of nodes per layer for each iteration of the model.\n",
    "layer1 = [600,550]\n",
    "layer2 = [600,500]\n",
    "layer3 = [600,400]\n",
    "layer4 = [600,300]\n",
    "layer5 = [600,200]\n",
    "layer6 = [600,100]\n",
    "layer7 = [700,650]\n",
    "layer8 = [700,600]\n",
    "layer9 = [700,500]\n",
    "layer10 = [700,400]\n",
    "layer11 = [700,300]\n",
    "layer12 = [700,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600, 550],\n",
       " [600, 500],\n",
       " [600, 400],\n",
       " [600, 300],\n",
       " [600, 200],\n",
       " [600, 100],\n",
       " [700, 650],\n",
       " [700, 600],\n",
       " [700, 500],\n",
       " [700, 400],\n",
       " [700, 300],\n",
       " [700, 200]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the layers to use in each iteration\n",
    "hidden_unit_items = [layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8,\n",
    "                     layer9, layer10, layer11, layer12]\n",
    "type(hidden_unit_items)\n",
    "hidden_unit_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to hold the results of each iteration.\n",
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "validation_performance_results = []\n",
    "processing_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-50-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 550]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmph_9ev64v\n",
      "\n",
      "Processing time (seconds): 163.875281\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975238\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-100-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 500]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp31sd16hh\n",
      "\n",
      "Processing time (seconds): 153.912467\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977381\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-200-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 400]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpx675vbtm\n",
      "\n",
      "Processing time (seconds): 137.655024\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975595\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-300-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp63w29jyr\n",
      "\n",
      "Processing time (seconds): 120.750260\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.976667\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-400-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 200]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpiq4df8i2\n",
      "\n",
      "Processing time (seconds): 113.476729\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.976667\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-500-Step-Funnel\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpdhcase92\n",
      "\n",
      "Processing time (seconds): 104.801969\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977143\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-50-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 650]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpwghn8g_b\n",
      "\n",
      "Processing time (seconds): 189.018758\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975119\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-100-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 600]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpj49155it\n",
      "\n",
      "Processing time (seconds): 180.718724\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.975000\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-200-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 500]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmplhttweej\n",
      "\n",
      "Processing time (seconds): 169.886834\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.978810\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-300-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 400]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpnrsg_8hk\n",
      "\n",
      "Processing time (seconds): 158.336167\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.976429\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-400-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 300]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpmvquz95n\n",
      "\n",
      "Processing time (seconds): 137.659403\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977738\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-700-Node-Max-per-Layer-500-Step-Funnel\n",
      "\n",
      "  Specification of method: [700, 200]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpakc3s6gi\n",
      "\n",
      "Processing time (seconds): 129.029486\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.976905\n"
     ]
    }
   ],
   "source": [
    "for name, unit in zip(names, hidden_unit_items):\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nMethod:', name)\n",
    "    print('\\n  Specification of method:', unit)\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "    dnn_clf = tf.estimator.DNNClassifier(hidden_units=unit, n_classes=10,\n",
    "                                         feature_columns=feature_cols)\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                        # to increase usability when uploaded to GitHub.\n",
    "            \n",
    "    # Train the model\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "    dnn_clf.train(input_fn=input_fn)\n",
    "    \n",
    "    end_time = time.clock() # end timer\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime)  # print process time to train model        \n",
    "    processing_time.append(runtime) # append process time results to list for comparison table\n",
    "        \n",
    "    # Evaluate the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "    train_eval_results = dnn_clf.evaluate(input_fn=train_input_fn) # training results\n",
    "    \n",
    "    valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_valid}, y=y_valid, shuffle=False)\n",
    "    valid_eval_results = dnn_clf.evaluate(input_fn=valid_input_fn) # validation results\n",
    "        \n",
    "    \n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = train_eval_results['accuracy']\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance) # append results to list for comparison table\n",
    "\n",
    "\n",
    "    # mean accuracy of prediction in test set\n",
    "    validation_performance = valid_eval_results['accuracy']\n",
    "    print(\"\\nValidation set accuracy: %f\" % validation_performance)\n",
    "    validation_performance_results.append(validation_performance) # append results to list for comparison table\n",
    "                \n",
    "    index_for_method += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine Tuning of Model: Tensorflow Deep Neural Networks\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Max Nodes per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-50-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>163.875281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-100-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>153.912467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-200-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>137.655024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-300-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>120.750260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-400-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>113.476729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-500-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>104.801969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-50-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>189.018758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-100-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>180.718724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-200-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>169.886834</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-300-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>158.336167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-400-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>137.659403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.977738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2-Layers-700-Node-Max-per-Layer-500-Step-Funnel</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>129.029486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Method Name  Layers  \\\n",
       "0    2-Layers-600-Node-Max-per-Layer-50-Step-Funnel       2   \n",
       "1   2-Layers-600-Node-Max-per-Layer-100-Step-Funnel       2   \n",
       "2   2-Layers-600-Node-Max-per-Layer-200-Step-Funnel       2   \n",
       "3   2-Layers-600-Node-Max-per-Layer-300-Step-Funnel       2   \n",
       "4   2-Layers-600-Node-Max-per-Layer-400-Step-Funnel       2   \n",
       "5   2-Layers-600-Node-Max-per-Layer-500-Step-Funnel       2   \n",
       "6    2-Layers-700-Node-Max-per-Layer-50-Step-Funnel       2   \n",
       "7   2-Layers-700-Node-Max-per-Layer-100-Step-Funnel       2   \n",
       "8   2-Layers-700-Node-Max-per-Layer-200-Step-Funnel       2   \n",
       "9   2-Layers-700-Node-Max-per-Layer-300-Step-Funnel       2   \n",
       "10  2-Layers-700-Node-Max-per-Layer-400-Step-Funnel       2   \n",
       "11  2-Layers-700-Node-Max-per-Layer-500-Step-Funnel       2   \n",
       "\n",
       "    Max Nodes per Layer  Processing Time  Training Set Accuracy  \\\n",
       "0                   600       163.875281                    1.0   \n",
       "1                   600       153.912467                    1.0   \n",
       "2                   600       137.655024                    1.0   \n",
       "3                   600       120.750260                    1.0   \n",
       "4                   600       113.476729                    1.0   \n",
       "5                   600       104.801969                    1.0   \n",
       "6                   700       189.018758                    1.0   \n",
       "7                   700       180.718724                    1.0   \n",
       "8                   700       169.886834                    1.0   \n",
       "9                   700       158.336167                    1.0   \n",
       "10                  700       137.659403                    1.0   \n",
       "11                  700       129.029486                    1.0   \n",
       "\n",
       "    Validation Set Accuracy  \n",
       "0                  0.975238  \n",
       "1                  0.977381  \n",
       "2                  0.975595  \n",
       "3                  0.976667  \n",
       "4                  0.976667  \n",
       "5                  0.977143  \n",
       "6                  0.975119  \n",
       "7                  0.975000  \n",
       "8                  0.978810  \n",
       "9                  0.976429  \n",
       "10                 0.977738  \n",
       "11                 0.976905  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to display results of this experiment\n",
    "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
    "                        ('Layers', Layers),\n",
    "                        ('Max Nodes per Layer', max_nodes_per_layer),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Validation Set Accuracy', validation_performance_results)]))\n",
    "\n",
    "print('\\nFine Tuning of Model: Tensorflow Deep Neural Networks\\n')\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 5: Fine Tuning of Model: Tensorflow Deep Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment used a loop was used to test several different step sizes between two layers to see how this impacts the model. It is clear from Table 5 that the model with the best score is one with 2-layers designed as a funnel with 600 nodes in the first layer and 100 nodes in the second layer.  This is the design that will be used going forward as the optimal model identified so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Tensorflow Neural Network Using Scikit-Learn\n",
    "### Test How Epoch Number Impacts Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that an good model has been developed in the previous two experiements, the intent of this model is to create a factoral design to evaluate how the number of epochs impacts the model.  An epoch is a unit of measure that is used to describe the entire dataset that is passed through a neural network model during training.  This means that one epoch is when the entire dataset has been passed forward and backward through the model exactly one time, and node connection weights are adjusted accordingly. This unit of measure is important because when training neural networks, the training dataset is often extremely large and prohibitive to pass through the model all at the same time.  Instead, the training dataset is broken up into batches and fed to the model in smaller groups.  Epochs are the measurement used to keep track of these batches and verify that the model is trained on every training observation.  \n",
    "\n",
    "When using only one epoch, the model is typically underfit as it has only been given the opporutnity to see the training data once in one particular batch.  Increasing the number of epochs during training essentially means that the model is seeing the entire dataset an increasing number of times, but with each epoch the batches are randomly selected, allowing the model to continually train the weights of each node connection to better fit the data.  When more epochs than necessary are used during training, the model can begin to overfit the data, which will be demonstrated by increasing training accuracies but a sudden decrase in validation accuracies.  Figure 5 from Sharma (2017) shows how a dataset may be impacted by a varying number of epochs.  The left graphic shows overfitting (too many epochs), the middle graphic shows an optimal fit (optimal number of epochs), and the right graphics shows underfitting (too few epochs).\n",
    "\n",
    "References: Sharma S. (2017, September 23). Epoch vs Batch Size vs Iterations. Retrieved from https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](DNNs_MNIST_GLAWSON_Fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 5: Impacts of Varying the Number of Epochs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the correct number of epochs is best done through experiementation, as the optimal number will vary with the data and diversity of each dataset.  The 8 epoch values evaluated in this experiment range from 5 to 500.  The first epoch value is relatively low, the next 5 epochs are midrange and have 10-epoch steps, and the last two epoch values will test much larger changes in this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create names for each iteration of the model\n",
    "names = ['2-Layers-600-Node-Max-per-Layer-Funnel-5-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-10-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-20-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-30-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-40-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-50-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-100-Epochs',\n",
    "         '2-Layers-600-Node-Max-per-Layer-Funnel-500-Epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs for each iteration of the model\n",
    "epochs = [5,10,20,30,40,50,100,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers for each iteration of the model\n",
    "Layers = [2, 2, 2, 2, 2, 2, 2, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the max number of nodes for each iteration of the model.  \n",
    "# This is just informational for the comparison table.\n",
    "max_nodes_per_layer = [600, 600, 600, 600, 600, 600, 600, 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of layers and number of nodes per layer for each iteration of the model.\n",
    "layer1 = [600,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[600, 100]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of the layers to use in each iteration\n",
    "hidden_unit_items = [layer1]\n",
    "type(hidden_unit_items)\n",
    "hidden_unit_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to hold the results of each iteration.\n",
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "validation_performance_results = []\n",
    "processing_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-5-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 5\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpfjszzv8u\n",
      "\n",
      "Processing time (seconds): 15.220140\n",
      "\n",
      "Training set accuracy: 0.993810\n",
      "\n",
      "Validation set accuracy: 0.971310\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-10-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 10\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp6p0ke06i\n",
      "\n",
      "Processing time (seconds): 28.436096\n",
      "\n",
      "Training set accuracy: 0.999643\n",
      "\n",
      "Validation set accuracy: 0.977024\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-20-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 20\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpuru_2ht4\n",
      "\n",
      "Processing time (seconds): 53.684456\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.979048\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-30-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 30\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp427gq57o\n",
      "\n",
      "Processing time (seconds): 79.477215\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977738\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-40-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 40\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpdpc_i0p9\n",
      "\n",
      "Processing time (seconds): 103.944204\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.979762\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-50-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 50\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpfoe_zcx2\n",
      "\n",
      "Processing time (seconds): 130.421620\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.978214\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-100-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 100\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmpgd6r2vbk\n",
      "\n",
      "Processing time (seconds): 262.079209\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.976905\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: 2-Layers-600-Node-Max-per-Layer-Funnel-500-Epochs\n",
      "\n",
      "  Specification of method: [600, 100]\n",
      "\n",
      "  Number of Epochs: 500\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmph3jd9t0g\n",
      "\n",
      "Processing time (seconds): 1297.400388\n",
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.978214\n"
     ]
    }
   ],
   "source": [
    "for name, epoch in zip(names, epochs):\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nMethod:', name)\n",
    "    print('\\n  Specification of method:', layer1)\n",
    "    print('\\n  Number of Epochs:', epoch)\n",
    "    start_time = time.clock()\n",
    "    \n",
    "    tf.set_random_seed(RANDOM_SEED)\n",
    "    feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "    dnn_clf = tf.estimator.DNNClassifier(hidden_units=layer1, n_classes=10,\n",
    "                                         feature_columns=feature_cols)\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                        # to increase usability when uploaded to GitHub.\n",
    "            \n",
    "    # Train the model\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, num_epochs=epoch, batch_size=50, shuffle=True)\n",
    "    dnn_clf.train(input_fn=input_fn)\n",
    "    \n",
    "    end_time = time.clock() # end timer\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime)  # print process time to train model        \n",
    "    processing_time.append(runtime) # append process time results to list for comparison table\n",
    "    \n",
    "    # Evaluate the model \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "    train_eval_results = dnn_clf.evaluate(input_fn=train_input_fn) # training results\n",
    "    \n",
    "    valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"X\": X_valid}, y=y_valid, shuffle=False)\n",
    "    valid_eval_results = dnn_clf.evaluate(input_fn=valid_input_fn) # validation results\n",
    "        \n",
    "    \n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = train_eval_results['accuracy']\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance) # append results to list for comparison table\n",
    "\n",
    "    # mean accuracy of prediction in test set\n",
    "    validation_performance = valid_eval_results['accuracy']\n",
    "    print(\"\\nValidation set accuracy: %f\" % validation_performance)\n",
    "    validation_performance_results.append(validation_performance) # append results to list for comparison table\n",
    "                \n",
    "    index_for_method += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch Impact Experiment: Tensorflow Deep Neural Networks\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Max Nodes per Layer</th>\n",
       "      <th>Processing Time</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-5-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>15.220140</td>\n",
       "      <td>0.993810</td>\n",
       "      <td>0.971310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-10-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>28.436096</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.977024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-20-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>53.684456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-30-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>79.477215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-40-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>103.944204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-50-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>130.421620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-100-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>262.079209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-Layers-600-Node-Max-per-Layer-Funnel-500-Epochs</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>1297.400388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Method Name  Layers  \\\n",
       "0    2-Layers-600-Node-Max-per-Layer-Funnel-5-Epochs       2   \n",
       "1   2-Layers-600-Node-Max-per-Layer-Funnel-10-Epochs       2   \n",
       "2   2-Layers-600-Node-Max-per-Layer-Funnel-20-Epochs       2   \n",
       "3   2-Layers-600-Node-Max-per-Layer-Funnel-30-Epochs       2   \n",
       "4   2-Layers-600-Node-Max-per-Layer-Funnel-40-Epochs       2   \n",
       "5   2-Layers-600-Node-Max-per-Layer-Funnel-50-Epochs       2   \n",
       "6  2-Layers-600-Node-Max-per-Layer-Funnel-100-Epochs       2   \n",
       "7  2-Layers-600-Node-Max-per-Layer-Funnel-500-Epochs       2   \n",
       "\n",
       "   Max Nodes per Layer  Processing Time  Training Set Accuracy  \\\n",
       "0                  600        15.220140               0.993810   \n",
       "1                  600        28.436096               0.999643   \n",
       "2                  600        53.684456               1.000000   \n",
       "3                  600        79.477215               1.000000   \n",
       "4                  600       103.944204               1.000000   \n",
       "5                  600       130.421620               1.000000   \n",
       "6                  600       262.079209               1.000000   \n",
       "7                  600      1297.400388               1.000000   \n",
       "\n",
       "   Validation Set Accuracy  \n",
       "0                 0.971310  \n",
       "1                 0.977024  \n",
       "2                 0.979048  \n",
       "3                 0.977738  \n",
       "4                 0.979762  \n",
       "5                 0.978214  \n",
       "6                 0.976905  \n",
       "7                 0.978214  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table to display results of this experiment\n",
    "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
    "                        ('Layers', Layers),\n",
    "                        ('Max Nodes per Layer', max_nodes_per_layer),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Validation Set Accuracy', validation_performance_results)]))\n",
    "\n",
    "print('\\nEpoch Impact Experiment: Tensorflow Deep Neural Networks\\n')\n",
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 6: Epoch Impact Experiment: Tensorflow Deep Neural Networks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment used a loop was used to test several different epoch numbers to see how this impacts the model.  It is clear from Table 6 that as more epochs are added, the model takes progressively more time to train.  However, using the accuracy of the validation set predictions as a determining factor, it is evident that more epochs does not always result in better accuracy for unseen data (in this case the validation data).  As has been discussed, too many epochs begins to lead to overfitting of the training data, reducing the ability for the model to generalize.  Using these results, 40 epochs appears to be the optimal value for accuracy and will be used for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what has been learned from the previous experiements, the best model identified so far will be used to make test predictions which will be submitted to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\DELL\\AppData\\Local\\Temp\\tmp_f3z131f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1ee436bfc50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the optimal number of layers and nodes to create a final model\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[600,100], n_classes=10,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                    # to increase usability when uploaded to GitHub.\n",
    "\n",
    "# Train the model\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set accuracy: 1.000000\n",
      "\n",
      "Validation set accuracy: 0.977857\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN) # surpress progress report, only show warnings.  This was added\n",
    "                                    # to increase usability when uploaded to GitHub.\n",
    "            \n",
    "# Check the accuracy one more time\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, shuffle=False)\n",
    "train_eval_results = dnn_clf.evaluate(input_fn=train_input_fn) # training results\n",
    "\n",
    "valid_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_valid}, y=y_valid, shuffle=False)\n",
    "valid_eval_results = dnn_clf.evaluate(input_fn=valid_input_fn) # validation results\n",
    "\n",
    "\n",
    "# mean accuracy of prediction in training set\n",
    "training_performance = train_eval_results['accuracy']\n",
    "print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "training_performance_results.append(training_performance) # append results to list for comparison table\n",
    "\n",
    "# mean accuracy of prediction in test set\n",
    "validation_performance = valid_eval_results['accuracy']\n",
    "print(\"\\nValidation set accuracy: %f\" % validation_performance)\n",
    "validation_performance_results.append(validation_performance) # append results to list for comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, shuffle=False)\n",
    "\n",
    "predictions = list(dnn_clf.predict(input_fn=test_input_fn))\n",
    "predicted_classes = [p[\"class_ids\"] for p in predictions]\n",
    "preds = [i[0] for i in predicted_classes]\n",
    "\n",
    "d = {'Label': preds}\n",
    "predictions_df = pd.DataFrame(data=d)\n",
    "\n",
    "np.savetxt('predit_submission.csv', \n",
    "                  np.c_[range(1,len(X_test)+1),predictions_df], \n",
    "                  delimiter=',', \n",
    "                  header = 'ImageId,Label', \n",
    "                  comments = '', \n",
    "                  fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous experiements were used to help focus in on the correct hyperparameters to chose to optimize this DNN model.  This final model used a 2-layer funnel design with the first layer having 600 nodes and the second layer having 100 nodes.  A total of 40 epochs were used to train the model.  The final accuracy of the validation set is pretty impressive at 0.978691.  The predictions made using this model were submitted to Kaggle with the following results.    \n",
    "\n",
    "Kaggle Submit Date: 3/26/2019\n",
    "\n",
    "Kaggle Score: 0.97614\n",
    "\n",
    "Kaggle Competition Rank: 1789\n",
    "\n",
    "Kaggle User ID: GaryLawson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Tensorflow Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Scikit-Learn API to develop DNNs was pretty straightforward, but having a full Tensorflow model in the toolkit is great to have.  Model 4 will look to mimic the final model identified using the experiements conducted above.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 600\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=RANDOM_SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate) # AdaGrad is the default optimizer for DNNClassifier()\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.98 Val accuracy: 0.91511905\n",
      "1 Batch accuracy: 0.86 Val accuracy: 0.9347619\n",
      "2 Batch accuracy: 0.96 Val accuracy: 0.9432143\n",
      "3 Batch accuracy: 0.96 Val accuracy: 0.9486905\n",
      "4 Batch accuracy: 1.0 Val accuracy: 0.9545238\n",
      "5 Batch accuracy: 0.96 Val accuracy: 0.95738095\n",
      "6 Batch accuracy: 0.98 Val accuracy: 0.9597619\n",
      "7 Batch accuracy: 0.96 Val accuracy: 0.96130955\n",
      "8 Batch accuracy: 1.0 Val accuracy: 0.9635714\n",
      "9 Batch accuracy: 0.96 Val accuracy: 0.96559525\n",
      "10 Batch accuracy: 0.98 Val accuracy: 0.965\n",
      "11 Batch accuracy: 0.94 Val accuracy: 0.96738094\n",
      "12 Batch accuracy: 1.0 Val accuracy: 0.96940476\n",
      "13 Batch accuracy: 0.96 Val accuracy: 0.9690476\n",
      "14 Batch accuracy: 0.98 Val accuracy: 0.97083336\n",
      "15 Batch accuracy: 0.98 Val accuracy: 0.9720238\n",
      "16 Batch accuracy: 0.98 Val accuracy: 0.97238094\n",
      "17 Batch accuracy: 0.98 Val accuracy: 0.97261906\n",
      "18 Batch accuracy: 1.0 Val accuracy: 0.97238094\n",
      "19 Batch accuracy: 1.0 Val accuracy: 0.97369045\n",
      "20 Batch accuracy: 1.0 Val accuracy: 0.9742857\n",
      "21 Batch accuracy: 1.0 Val accuracy: 0.97321427\n",
      "22 Batch accuracy: 1.0 Val accuracy: 0.97309524\n",
      "23 Batch accuracy: 1.0 Val accuracy: 0.97380954\n",
      "24 Batch accuracy: 1.0 Val accuracy: 0.9739286\n",
      "25 Batch accuracy: 0.98 Val accuracy: 0.9745238\n",
      "26 Batch accuracy: 1.0 Val accuracy: 0.97380954\n",
      "27 Batch accuracy: 1.0 Val accuracy: 0.975\n",
      "28 Batch accuracy: 1.0 Val accuracy: 0.97488093\n",
      "29 Batch accuracy: 1.0 Val accuracy: 0.975\n",
      "30 Batch accuracy: 1.0 Val accuracy: 0.97511905\n",
      "31 Batch accuracy: 1.0 Val accuracy: 0.9753571\n",
      "32 Batch accuracy: 1.0 Val accuracy: 0.9760714\n",
      "33 Batch accuracy: 1.0 Val accuracy: 0.97559524\n",
      "34 Batch accuracy: 1.0 Val accuracy: 0.9753571\n",
      "35 Batch accuracy: 1.0 Val accuracy: 0.9753571\n",
      "36 Batch accuracy: 1.0 Val accuracy: 0.97642857\n",
      "37 Batch accuracy: 1.0 Val accuracy: 0.9759524\n",
      "38 Batch accuracy: 1.0 Val accuracy: 0.97630954\n",
      "39 Batch accuracy: 1.0 Val accuracy: 0.97583336\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./MNIST_tf_Model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./MNIST_tf_Model.ckpt\") # or better, use save_path\n",
    "    Z = logits.eval(feed_dict={X: X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Label': y_pred}\n",
    "predictions_df = pd.DataFrame(data=d)\n",
    "\n",
    "predictions_df.index = np.arange(1, len(predictions_df) + 1)\n",
    "predictions_df.index.name = 'ImageID'\n",
    "\n",
    "predictions_df.to_csv('predit_submission_tf.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Tensorflow model is much more involved than using the Scikit-Learn API, but adds additional flexibility.  To become proficient with the use of Tensorflow, a much stronger understanding of neural networks and the mathematics behind how they are built and optimized is recommended.\n",
    "\n",
    "Using the same hyperparameters, this model scores right in line with the model developed earlier using the Scikit-Learn API. This is expected because the Scikit-Learn API uses Tensorflow on the back end to build, train, and use the DNN.\n",
    "\n",
    "The predictions made using this model were submitted to Kaggle with the following results.    \n",
    "\n",
    "Kaggle Submit Date: 3/26/2019\n",
    "\n",
    "Kaggle Score: 0.97642\n",
    "\n",
    "Kaggle Competition Rank: 1780\n",
    "\n",
    "Kaggle User ID: GaryLawson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 - Keras Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model that will use Keras to mimic the models above.  Keras is another high-level neural network API that runs ontop of Tensorflow to help increase usability when developing and training DNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y variables into categorical for use in Keras\n",
    "y_train_keras = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid_keras = tf.keras.utils.to_categorical(y_valid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the model\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 600\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/40\n",
      "33600/33600 [==============================] - 7s 194us/step - loss: 0.2316 - categorical_accuracy: 0.9308 - val_loss: 0.1274 - val_categorical_accuracy: 0.9607\n",
      "Epoch 2/40\n",
      "33600/33600 [==============================] - 6s 183us/step - loss: 0.0946 - categorical_accuracy: 0.9718 - val_loss: 0.0962 - val_categorical_accuracy: 0.9700\n",
      "Epoch 3/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0639 - categorical_accuracy: 0.9814 - val_loss: 0.0898 - val_categorical_accuracy: 0.9729\n",
      "Epoch 4/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0464 - categorical_accuracy: 0.9869 - val_loss: 0.0825 - val_categorical_accuracy: 0.9744\n",
      "Epoch 5/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0351 - categorical_accuracy: 0.9907 - val_loss: 0.0752 - val_categorical_accuracy: 0.9775\n",
      "Epoch 6/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0267 - categorical_accuracy: 0.9939 - val_loss: 0.0754 - val_categorical_accuracy: 0.9775\n",
      "Epoch 7/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0204 - categorical_accuracy: 0.9962 - val_loss: 0.0741 - val_categorical_accuracy: 0.9781\n",
      "Epoch 8/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0162 - categorical_accuracy: 0.9972 - val_loss: 0.0726 - val_categorical_accuracy: 0.9774\n",
      "Epoch 9/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0130 - categorical_accuracy: 0.9984 - val_loss: 0.0720 - val_categorical_accuracy: 0.9783\n",
      "Epoch 10/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0104 - categorical_accuracy: 0.9990 - val_loss: 0.0710 - val_categorical_accuracy: 0.9795\n",
      "Epoch 11/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0087 - categorical_accuracy: 0.9993 - val_loss: 0.0725 - val_categorical_accuracy: 0.9787\n",
      "Epoch 12/40\n",
      "33600/33600 [==============================] - 6s 183us/step - loss: 0.0071 - categorical_accuracy: 0.9995 - val_loss: 0.0711 - val_categorical_accuracy: 0.9794\n",
      "Epoch 13/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0062 - categorical_accuracy: 0.9996 - val_loss: 0.0723 - val_categorical_accuracy: 0.9788\n",
      "Epoch 14/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0052 - categorical_accuracy: 0.9998 - val_loss: 0.0715 - val_categorical_accuracy: 0.9796\n",
      "Epoch 15/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0045 - categorical_accuracy: 0.9998 - val_loss: 0.0722 - val_categorical_accuracy: 0.9794\n",
      "Epoch 16/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0039 - categorical_accuracy: 0.9999 - val_loss: 0.0729 - val_categorical_accuracy: 0.9795\n",
      "Epoch 17/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0035 - categorical_accuracy: 0.9999 - val_loss: 0.0728 - val_categorical_accuracy: 0.9796\n",
      "Epoch 18/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 0.0733 - val_categorical_accuracy: 0.9793\n",
      "Epoch 19/40\n",
      "33600/33600 [==============================] - 6s 184us/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 0.0731 - val_categorical_accuracy: 0.9794\n",
      "Epoch 20/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0025 - categorical_accuracy: 1.0000 - val_loss: 0.0742 - val_categorical_accuracy: 0.9801\n",
      "Epoch 21/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.0746 - val_categorical_accuracy: 0.9798\n",
      "Epoch 22/40\n",
      "33600/33600 [==============================] - 6s 184us/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.0745 - val_categorical_accuracy: 0.9800\n",
      "Epoch 23/40\n",
      "33600/33600 [==============================] - 6s 187us/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.0755 - val_categorical_accuracy: 0.9796\n",
      "Epoch 24/40\n",
      "33600/33600 [==============================] - 6s 183us/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.0753 - val_categorical_accuracy: 0.9801\n",
      "Epoch 25/40\n",
      "33600/33600 [==============================] - 7s 195us/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 0.0750 - val_categorical_accuracy: 0.9801\n",
      "Epoch 26/40\n",
      "33600/33600 [==============================] - 7s 195us/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.0756 - val_categorical_accuracy: 0.9802\n",
      "Epoch 27/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.0766 - val_categorical_accuracy: 0.9799\n",
      "Epoch 28/40\n",
      "33600/33600 [==============================] - 6s 190us/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0762 - val_categorical_accuracy: 0.9800\n",
      "Epoch 29/40\n",
      "33600/33600 [==============================] - 6s 184us/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.0763 - val_categorical_accuracy: 0.9799\n",
      "Epoch 30/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.0765 - val_categorical_accuracy: 0.9798\n",
      "Epoch 31/40\n",
      "33600/33600 [==============================] - 6s 189us/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0766 - val_categorical_accuracy: 0.9799\n",
      "Epoch 32/40\n",
      "33600/33600 [==============================] - 6s 182us/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.0770 - val_categorical_accuracy: 0.9801\n",
      "Epoch 33/40\n",
      "33600/33600 [==============================] - 6s 188us/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.0774 - val_categorical_accuracy: 0.9802\n",
      "Epoch 34/40\n",
      "33600/33600 [==============================] - 6s 183us/step - loss: 9.5751e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0774 - val_categorical_accuracy: 0.9804\n",
      "Epoch 35/40\n",
      "33600/33600 [==============================] - 6s 189us/step - loss: 9.1682e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0776 - val_categorical_accuracy: 0.9800\n",
      "Epoch 36/40\n",
      "33600/33600 [==============================] - 6s 189us/step - loss: 8.7439e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0783 - val_categorical_accuracy: 0.9802\n",
      "Epoch 37/40\n",
      "33600/33600 [==============================] - 6s 183us/step - loss: 8.3417e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0788 - val_categorical_accuracy: 0.9801\n",
      "Epoch 38/40\n",
      "33600/33600 [==============================] - 6s 189us/step - loss: 8.0103e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0783 - val_categorical_accuracy: 0.9805\n",
      "Epoch 39/40\n",
      "33600/33600 [==============================] - 6s 184us/step - loss: 7.6676e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0787 - val_categorical_accuracy: 0.9804\n",
      "Epoch 40/40\n",
      "33600/33600 [==============================] - 6s 190us/step - loss: 7.3633e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0794 - val_categorical_accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "# Initiate model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(layers.Dense(n_hidden1,input_dim=n_inputs,activation='relu'))\n",
    "model.add(layers.Dense(n_hidden2,input_dim=n_inputs,activation='relu'))\n",
    "\n",
    "# Add output layer and activation\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "# Set Optimizer and Loss function.  Use AdaGrad since this is what was used in Scikit-Learn DNNClassifier()\n",
    "model.compile(optimizer=\"adagrad\", loss='categorical_crossentropy',metrics=['categorical_accuracy']) \n",
    "history=model.fit(X_train, y_train_keras, epochs=n_epochs, validation_data=(X_valid, y_valid_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions, reshape, and save to csv file\n",
    "mypred=model.predict(X_test)\n",
    "\n",
    "label = np.argmax(mypred, axis=1)\n",
    "\n",
    "test_id = np.reshape(range(1, len(mypred) + 1), label.shape)\n",
    "\n",
    "my_submission = pd.DataFrame({'ImageId': test_id, 'Label': label})\n",
    "my_submission.to_csv('predit_submission_keras.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.231572</td>\n",
       "      <td>0.930774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096223</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.094623</td>\n",
       "      <td>0.971756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.089779</td>\n",
       "      <td>0.972857</td>\n",
       "      <td>0.063940</td>\n",
       "      <td>0.981399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.974405</td>\n",
       "      <td>0.046362</td>\n",
       "      <td>0.986935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075182</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.990655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.075444</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.026660</td>\n",
       "      <td>0.993899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074111</td>\n",
       "      <td>0.978095</td>\n",
       "      <td>0.020402</td>\n",
       "      <td>0.996220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.977381</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.997173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.072026</td>\n",
       "      <td>0.978333</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.998393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.071015</td>\n",
       "      <td>0.979524</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.998958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.072533</td>\n",
       "      <td>0.978690</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>0.999256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.071072</td>\n",
       "      <td>0.979405</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.999494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.072285</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.006163</td>\n",
       "      <td>0.999583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.072181</td>\n",
       "      <td>0.979405</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.072909</td>\n",
       "      <td>0.979524</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.072794</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.073265</td>\n",
       "      <td>0.979286</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.073147</td>\n",
       "      <td>0.979405</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.074216</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.074578</td>\n",
       "      <td>0.979762</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.074517</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.075538</td>\n",
       "      <td>0.979643</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.075293</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.075042</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.075612</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.076550</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.076229</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.076330</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.076521</td>\n",
       "      <td>0.979762</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.076643</td>\n",
       "      <td>0.979881</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.077035</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.077387</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.077446</td>\n",
       "      <td>0.980357</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.077554</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.078274</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.078790</td>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.078251</td>\n",
       "      <td>0.980476</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.078747</td>\n",
       "      <td>0.980357</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.079360</td>\n",
       "      <td>0.980357</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  val_categorical_accuracy      loss  categorical_accuracy\n",
       "0   0.127401                  0.960714  0.231572              0.930774\n",
       "1   0.096223                  0.970000  0.094623              0.971756\n",
       "2   0.089779                  0.972857  0.063940              0.981399\n",
       "3   0.082523                  0.974405  0.046362              0.986935\n",
       "4   0.075182                  0.977500  0.035088              0.990655\n",
       "5   0.075444                  0.977500  0.026660              0.993899\n",
       "6   0.074111                  0.978095  0.020402              0.996220\n",
       "7   0.072581                  0.977381  0.016217              0.997173\n",
       "8   0.072026                  0.978333  0.012956              0.998393\n",
       "9   0.071015                  0.979524  0.010433              0.998958\n",
       "10  0.072533                  0.978690  0.008738              0.999256\n",
       "11  0.071072                  0.979405  0.007142              0.999494\n",
       "12  0.072285                  0.978810  0.006163              0.999583\n",
       "13  0.071483                  0.979643  0.005200              0.999821\n",
       "14  0.072181                  0.979405  0.004548              0.999821\n",
       "15  0.072909                  0.979524  0.003933              0.999881\n",
       "16  0.072794                  0.979643  0.003504              0.999881\n",
       "17  0.073265                  0.979286  0.003047              1.000000\n",
       "18  0.073147                  0.979405  0.002732              1.000000\n",
       "19  0.074216                  0.980119  0.002484              1.000000\n",
       "20  0.074578                  0.979762  0.002270              1.000000\n",
       "21  0.074517                  0.980000  0.002060              1.000000\n",
       "22  0.075538                  0.979643  0.001901              1.000000\n",
       "23  0.075293                  0.980119  0.001773              1.000000\n",
       "24  0.075042                  0.980119  0.001633              1.000000\n",
       "25  0.075612                  0.980238  0.001529              1.000000\n",
       "26  0.076550                  0.979881  0.001423              1.000000\n",
       "27  0.076229                  0.980000  0.001339              1.000000\n",
       "28  0.076330                  0.979881  0.001267              1.000000\n",
       "29  0.076521                  0.979762  0.001183              1.000000\n",
       "30  0.076643                  0.979881  0.001122              1.000000\n",
       "31  0.077035                  0.980119  0.001065              1.000000\n",
       "32  0.077387                  0.980238  0.001012              1.000000\n",
       "33  0.077446                  0.980357  0.000958              1.000000\n",
       "34  0.077554                  0.980000  0.000917              1.000000\n",
       "35  0.078274                  0.980238  0.000874              1.000000\n",
       "36  0.078790                  0.980119  0.000834              1.000000\n",
       "37  0.078251                  0.980476  0.000801              1.000000\n",
       "38  0.078747                  0.980357  0.000767              1.000000\n",
       "39  0.079360                  0.980357  0.000736              1.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a table of the results by epoch for easier review\n",
    "mytable=pd.DataFrame(history.history)\n",
    "mytable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Table 7: DNN Results by Epoch Using Keras</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Plot####\n",
    "#print(history.history.keys())\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Figure 6: Model Accuracy and Model Loss as a Function of the Number of Epochs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras has again provided similar results to the Scikit-Learn API and the Tensorflow model, though this Keras model does seem to provide better accruacy when using the same hyperparameters.  While the increase in validation accuracy appears to result in an increased accuracy in the Kaggle competition as well, this may be due to the random nature of the DNN graph weights being initiated in each version of the model.\n",
    "\n",
    "Keras has streamlined the use of Tensorflow, but kept most of the ability to customize the development of a DNN.  With this model, graphs showing the Model Accuracy and Model Loss with each epoch are displayed in Figure 6, helping to provide a visual of how the model is learning and then teaching itself in each epoch.\n",
    "\n",
    "The predictions made using this model were submitted to Kaggle with the following results.    \n",
    "\n",
    "Kaggle Submit Date: 3/26/2019\n",
    "\n",
    "Kaggle Score: 0.97714\n",
    "\n",
    "Kaggle Competition Rank: 1755\n",
    "\n",
    "Kaggle User ID: GaryLawson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep neural networks are an amazing tool in the machine learning space that have revolutionized the ability for models to leverage data to learn how combinations of features impact the target response variable with little guidance from the data scientist.  In a lot of cases the result can be an increased level of target response predictions when compared to other machine learning methods.  \n",
    "\n",
    "As seen with this example of handwritten digits, DNNs have a lot of promise and can be trained relatively quickly, and ulitimately provide terrific accuracy.  From a business standpoint, an experiment like this shows that DNNs can offer opportunities to help reduce costs through automation of image recognition and increase accuracy by limiting the amount of manual human interaction that is required to review such images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
